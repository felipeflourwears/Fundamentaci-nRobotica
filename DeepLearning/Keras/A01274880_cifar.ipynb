{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('ai': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "A01274880_cifar.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "c633da67cca8c9012768cec5592dfea837eb018155654bdd63f161c159c521d5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVCR_J6F6Tvs"
      },
      "source": [
        "# Deep learning steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7nflKCE6Tvv"
      },
      "source": [
        "#### Gather the dataset\n",
        "\n",
        "The first component of building a deep learning network is to gather our initial dataset. We need the data itself as well as the labels associated with each data point. These labels should come from a finite set of categories, such as: categories = dog, cat, panda.\n",
        "\n",
        "#### Split Your Dataset \n",
        "\n",
        "Now that we have our initial dataset, we need to split it into two parts: 1. A training set 2. A testing set A training set is used by our classifier to “learn” what each category looks like by making predictions on the input data and then correct itself when predictions are wrong. After the classifier has been trained, we can evaluate the performing on a testing set. Here are some common data splits:\n",
        "\n",
        "![data splits](https://github.com/octavio-navarro/DL-Course-Material/blob/master/Notebooks/images/test_train_split.png?raw=1)\n",
        "\n",
        "You should create a third data split called the validation set. This set of the data (normally) comes from the training data and is used as “fake test data” to tune the hyperparameters. Only after have we determined the hyperparameter values using the validation set do we move on to collecting final accuracy results in the testing data. We normally allocate roughly 10-20% of the training data for validation.\n",
        "\n",
        "#### Train the network\n",
        "\n",
        "Given our training set of images, we can now train our network. The goal here is for our network to learn how to recognize each of the categories in our labeled data. When the model makes a mistake, it learns from this mistake and improves itself.\n",
        "\n",
        "#### Evaluate\n",
        "\n",
        "Last, we need to evaluate our trained network. For each of the data in our testing set, we present them to the network and ask it to predict what it thinks the label of the data is. These model predictions are compared to the ground-truth labels from our testing set. The ground-truth labels represent what the data category actually is. From there, we can compute the number of predictions our classifier got correct and compute aggregate reports such as precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NUTBggq6Tvw"
      },
      "source": [
        "# Keras\n",
        "\n",
        "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation.\n",
        "\n",
        "Keras allows:\n",
        "\n",
        "1. Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n",
        "2. Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n",
        "3. Runs seamlessly on CPU and GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc6_6lVm6Tvx"
      },
      "source": [
        "# Mnist with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0jQFA_M6Tvx"
      },
      "source": [
        "#### Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYLA9Mg96Tvx",
        "outputId": "5870b93f-6475-4145-ba34-7717c9e6026e"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import models, layers \n",
        "\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "\n",
        "#from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"Tensforflow version:{tf.__version__}\")\n",
        "print(f\"Keras version:{tf.keras.__version__}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensforflow version:2.8.0\n",
            "Keras version:2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargar data set de CIFAR\n",
        "tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "gVvP4RvjHtiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4d8ada-0293-4a27-fb59-6fd477c1efe8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "170508288/170498071 [==============================] - 4s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[[[ 59,  62,  63],\n",
              "           [ 43,  46,  45],\n",
              "           [ 50,  48,  43],\n",
              "           ...,\n",
              "           [158, 132, 108],\n",
              "           [152, 125, 102],\n",
              "           [148, 124, 103]],\n",
              "  \n",
              "          [[ 16,  20,  20],\n",
              "           [  0,   0,   0],\n",
              "           [ 18,   8,   0],\n",
              "           ...,\n",
              "           [123,  88,  55],\n",
              "           [119,  83,  50],\n",
              "           [122,  87,  57]],\n",
              "  \n",
              "          [[ 25,  24,  21],\n",
              "           [ 16,   7,   0],\n",
              "           [ 49,  27,   8],\n",
              "           ...,\n",
              "           [118,  84,  50],\n",
              "           [120,  84,  50],\n",
              "           [109,  73,  42]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[208, 170,  96],\n",
              "           [201, 153,  34],\n",
              "           [198, 161,  26],\n",
              "           ...,\n",
              "           [160, 133,  70],\n",
              "           [ 56,  31,   7],\n",
              "           [ 53,  34,  20]],\n",
              "  \n",
              "          [[180, 139,  96],\n",
              "           [173, 123,  42],\n",
              "           [186, 144,  30],\n",
              "           ...,\n",
              "           [184, 148,  94],\n",
              "           [ 97,  62,  34],\n",
              "           [ 83,  53,  34]],\n",
              "  \n",
              "          [[177, 144, 116],\n",
              "           [168, 129,  94],\n",
              "           [179, 142,  87],\n",
              "           ...,\n",
              "           [216, 184, 140],\n",
              "           [151, 118,  84],\n",
              "           [123,  92,  72]]],\n",
              "  \n",
              "  \n",
              "         [[[154, 177, 187],\n",
              "           [126, 137, 136],\n",
              "           [105, 104,  95],\n",
              "           ...,\n",
              "           [ 91,  95,  71],\n",
              "           [ 87,  90,  71],\n",
              "           [ 79,  81,  70]],\n",
              "  \n",
              "          [[140, 160, 169],\n",
              "           [145, 153, 154],\n",
              "           [125, 125, 118],\n",
              "           ...,\n",
              "           [ 96,  99,  78],\n",
              "           [ 77,  80,  62],\n",
              "           [ 71,  73,  61]],\n",
              "  \n",
              "          [[140, 155, 164],\n",
              "           [139, 146, 149],\n",
              "           [115, 115, 112],\n",
              "           ...,\n",
              "           [ 79,  82,  64],\n",
              "           [ 68,  70,  55],\n",
              "           [ 67,  69,  55]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[175, 167, 166],\n",
              "           [156, 154, 160],\n",
              "           [154, 160, 170],\n",
              "           ...,\n",
              "           [ 42,  34,  36],\n",
              "           [ 61,  53,  57],\n",
              "           [ 93,  83,  91]],\n",
              "  \n",
              "          [[165, 154, 128],\n",
              "           [156, 152, 130],\n",
              "           [159, 161, 142],\n",
              "           ...,\n",
              "           [103,  93,  96],\n",
              "           [123, 114, 120],\n",
              "           [131, 121, 131]],\n",
              "  \n",
              "          [[163, 148, 120],\n",
              "           [158, 148, 122],\n",
              "           [163, 156, 133],\n",
              "           ...,\n",
              "           [143, 133, 139],\n",
              "           [143, 134, 142],\n",
              "           [143, 133, 144]]],\n",
              "  \n",
              "  \n",
              "         [[[255, 255, 255],\n",
              "           [253, 253, 253],\n",
              "           [253, 253, 253],\n",
              "           ...,\n",
              "           [253, 253, 253],\n",
              "           [253, 253, 253],\n",
              "           [253, 253, 253]],\n",
              "  \n",
              "          [[255, 255, 255],\n",
              "           [255, 255, 255],\n",
              "           [255, 255, 255],\n",
              "           ...,\n",
              "           [255, 255, 255],\n",
              "           [255, 255, 255],\n",
              "           [255, 255, 255]],\n",
              "  \n",
              "          [[255, 255, 255],\n",
              "           [254, 254, 254],\n",
              "           [254, 254, 254],\n",
              "           ...,\n",
              "           [254, 254, 254],\n",
              "           [254, 254, 254],\n",
              "           [254, 254, 254]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[113, 120, 112],\n",
              "           [111, 118, 111],\n",
              "           [105, 112, 106],\n",
              "           ...,\n",
              "           [ 72,  81,  80],\n",
              "           [ 72,  80,  79],\n",
              "           [ 72,  80,  79]],\n",
              "  \n",
              "          [[111, 118, 110],\n",
              "           [104, 111, 104],\n",
              "           [ 99, 106,  98],\n",
              "           ...,\n",
              "           [ 68,  75,  73],\n",
              "           [ 70,  76,  75],\n",
              "           [ 78,  84,  82]],\n",
              "  \n",
              "          [[106, 113, 105],\n",
              "           [ 99, 106,  98],\n",
              "           [ 95, 102,  94],\n",
              "           ...,\n",
              "           [ 78,  85,  83],\n",
              "           [ 79,  85,  83],\n",
              "           [ 80,  86,  84]]],\n",
              "  \n",
              "  \n",
              "         ...,\n",
              "  \n",
              "  \n",
              "         [[[ 35, 178, 235],\n",
              "           [ 40, 176, 239],\n",
              "           [ 42, 176, 241],\n",
              "           ...,\n",
              "           [ 99, 177, 219],\n",
              "           [ 79, 147, 197],\n",
              "           [ 89, 148, 189]],\n",
              "  \n",
              "          [[ 57, 182, 234],\n",
              "           [ 44, 184, 250],\n",
              "           [ 50, 183, 240],\n",
              "           ...,\n",
              "           [156, 182, 200],\n",
              "           [141, 177, 206],\n",
              "           [116, 149, 175]],\n",
              "  \n",
              "          [[ 98, 197, 237],\n",
              "           [ 64, 189, 252],\n",
              "           [ 69, 192, 245],\n",
              "           ...,\n",
              "           [188, 195, 206],\n",
              "           [119, 135, 147],\n",
              "           [ 61,  79,  90]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 73,  79,  77],\n",
              "           [ 53,  63,  68],\n",
              "           [ 54,  68,  80],\n",
              "           ...,\n",
              "           [ 17,  40,  64],\n",
              "           [ 21,  36,  51],\n",
              "           [ 33,  48,  49]],\n",
              "  \n",
              "          [[ 61,  68,  75],\n",
              "           [ 55,  70,  86],\n",
              "           [ 57,  79, 103],\n",
              "           ...,\n",
              "           [ 24,  48,  72],\n",
              "           [ 17,  35,  53],\n",
              "           [  7,  23,  32]],\n",
              "  \n",
              "          [[ 44,  56,  73],\n",
              "           [ 46,  66,  88],\n",
              "           [ 49,  77, 105],\n",
              "           ...,\n",
              "           [ 27,  52,  77],\n",
              "           [ 21,  43,  66],\n",
              "           [ 12,  31,  50]]],\n",
              "  \n",
              "  \n",
              "         [[[189, 211, 240],\n",
              "           [186, 208, 236],\n",
              "           [185, 207, 235],\n",
              "           ...,\n",
              "           [175, 195, 224],\n",
              "           [172, 194, 222],\n",
              "           [169, 194, 220]],\n",
              "  \n",
              "          [[194, 210, 239],\n",
              "           [191, 207, 236],\n",
              "           [190, 206, 235],\n",
              "           ...,\n",
              "           [173, 192, 220],\n",
              "           [171, 191, 218],\n",
              "           [167, 190, 216]],\n",
              "  \n",
              "          [[208, 219, 244],\n",
              "           [205, 216, 240],\n",
              "           [204, 215, 239],\n",
              "           ...,\n",
              "           [175, 191, 217],\n",
              "           [172, 190, 216],\n",
              "           [169, 191, 215]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[207, 199, 181],\n",
              "           [203, 195, 175],\n",
              "           [203, 196, 173],\n",
              "           ...,\n",
              "           [135, 132, 127],\n",
              "           [162, 158, 150],\n",
              "           [168, 163, 151]],\n",
              "  \n",
              "          [[198, 190, 170],\n",
              "           [189, 181, 159],\n",
              "           [180, 172, 147],\n",
              "           ...,\n",
              "           [178, 171, 160],\n",
              "           [175, 169, 156],\n",
              "           [175, 169, 154]],\n",
              "  \n",
              "          [[198, 189, 173],\n",
              "           [189, 181, 162],\n",
              "           [178, 170, 149],\n",
              "           ...,\n",
              "           [195, 184, 169],\n",
              "           [196, 189, 171],\n",
              "           [195, 190, 171]]],\n",
              "  \n",
              "  \n",
              "         [[[229, 229, 239],\n",
              "           [236, 237, 247],\n",
              "           [234, 236, 247],\n",
              "           ...,\n",
              "           [217, 219, 233],\n",
              "           [221, 223, 234],\n",
              "           [222, 223, 233]],\n",
              "  \n",
              "          [[222, 221, 229],\n",
              "           [239, 239, 249],\n",
              "           [233, 234, 246],\n",
              "           ...,\n",
              "           [223, 223, 236],\n",
              "           [227, 228, 238],\n",
              "           [210, 211, 220]],\n",
              "  \n",
              "          [[213, 206, 211],\n",
              "           [234, 232, 239],\n",
              "           [231, 233, 244],\n",
              "           ...,\n",
              "           [220, 220, 232],\n",
              "           [220, 219, 232],\n",
              "           [202, 203, 215]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[150, 143, 135],\n",
              "           [140, 135, 127],\n",
              "           [132, 127, 120],\n",
              "           ...,\n",
              "           [224, 222, 218],\n",
              "           [230, 228, 225],\n",
              "           [241, 241, 238]],\n",
              "  \n",
              "          [[137, 132, 126],\n",
              "           [130, 127, 120],\n",
              "           [125, 121, 115],\n",
              "           ...,\n",
              "           [181, 180, 178],\n",
              "           [202, 201, 198],\n",
              "           [212, 211, 207]],\n",
              "  \n",
              "          [[122, 119, 114],\n",
              "           [118, 116, 110],\n",
              "           [120, 116, 111],\n",
              "           ...,\n",
              "           [179, 177, 173],\n",
              "           [164, 164, 162],\n",
              "           [163, 163, 161]]]], dtype=uint8), array([[6],\n",
              "         [9],\n",
              "         [9],\n",
              "         ...,\n",
              "         [9],\n",
              "         [1],\n",
              "         [1]], dtype=uint8)), (array([[[[158, 112,  49],\n",
              "           [159, 111,  47],\n",
              "           [165, 116,  51],\n",
              "           ...,\n",
              "           [137,  95,  36],\n",
              "           [126,  91,  36],\n",
              "           [116,  85,  33]],\n",
              "  \n",
              "          [[152, 112,  51],\n",
              "           [151, 110,  40],\n",
              "           [159, 114,  45],\n",
              "           ...,\n",
              "           [136,  95,  31],\n",
              "           [125,  91,  32],\n",
              "           [119,  88,  34]],\n",
              "  \n",
              "          [[151, 110,  47],\n",
              "           [151, 109,  33],\n",
              "           [158, 111,  36],\n",
              "           ...,\n",
              "           [139,  98,  34],\n",
              "           [130,  95,  34],\n",
              "           [120,  89,  33]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 68, 124, 177],\n",
              "           [ 42, 100, 148],\n",
              "           [ 31,  88, 137],\n",
              "           ...,\n",
              "           [ 38,  97, 146],\n",
              "           [ 13,  64, 108],\n",
              "           [ 40,  85, 127]],\n",
              "  \n",
              "          [[ 61, 116, 168],\n",
              "           [ 49, 102, 148],\n",
              "           [ 35,  85, 132],\n",
              "           ...,\n",
              "           [ 26,  82, 130],\n",
              "           [ 29,  82, 126],\n",
              "           [ 20,  64, 107]],\n",
              "  \n",
              "          [[ 54, 107, 160],\n",
              "           [ 56, 105, 149],\n",
              "           [ 45,  89, 132],\n",
              "           ...,\n",
              "           [ 24,  77, 124],\n",
              "           [ 34,  84, 129],\n",
              "           [ 21,  67, 110]]],\n",
              "  \n",
              "  \n",
              "         [[[235, 235, 235],\n",
              "           [231, 231, 231],\n",
              "           [232, 232, 232],\n",
              "           ...,\n",
              "           [233, 233, 233],\n",
              "           [233, 233, 233],\n",
              "           [232, 232, 232]],\n",
              "  \n",
              "          [[238, 238, 238],\n",
              "           [235, 235, 235],\n",
              "           [235, 235, 235],\n",
              "           ...,\n",
              "           [236, 236, 236],\n",
              "           [236, 236, 236],\n",
              "           [235, 235, 235]],\n",
              "  \n",
              "          [[237, 237, 237],\n",
              "           [234, 234, 234],\n",
              "           [234, 234, 234],\n",
              "           ...,\n",
              "           [235, 235, 235],\n",
              "           [235, 235, 235],\n",
              "           [234, 234, 234]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 87,  99,  89],\n",
              "           [ 43,  51,  37],\n",
              "           [ 19,  23,  11],\n",
              "           ...,\n",
              "           [169, 184, 179],\n",
              "           [182, 197, 193],\n",
              "           [188, 202, 201]],\n",
              "  \n",
              "          [[ 82,  96,  82],\n",
              "           [ 46,  57,  36],\n",
              "           [ 36,  44,  22],\n",
              "           ...,\n",
              "           [174, 189, 183],\n",
              "           [185, 200, 196],\n",
              "           [187, 202, 200]],\n",
              "  \n",
              "          [[ 85, 101,  83],\n",
              "           [ 62,  75,  48],\n",
              "           [ 58,  67,  38],\n",
              "           ...,\n",
              "           [168, 183, 178],\n",
              "           [180, 195, 191],\n",
              "           [186, 200, 199]]],\n",
              "  \n",
              "  \n",
              "         [[[158, 190, 222],\n",
              "           [158, 187, 218],\n",
              "           [139, 166, 194],\n",
              "           ...,\n",
              "           [228, 231, 234],\n",
              "           [237, 239, 243],\n",
              "           [238, 241, 246]],\n",
              "  \n",
              "          [[170, 200, 229],\n",
              "           [172, 199, 226],\n",
              "           [151, 176, 201],\n",
              "           ...,\n",
              "           [232, 232, 236],\n",
              "           [246, 246, 250],\n",
              "           [246, 247, 251]],\n",
              "  \n",
              "          [[174, 201, 225],\n",
              "           [176, 200, 222],\n",
              "           [157, 179, 199],\n",
              "           ...,\n",
              "           [230, 229, 232],\n",
              "           [250, 249, 251],\n",
              "           [245, 244, 247]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 31,  40,  45],\n",
              "           [ 30,  39,  44],\n",
              "           [ 26,  35,  40],\n",
              "           ...,\n",
              "           [ 37,  40,  46],\n",
              "           [  9,  13,  14],\n",
              "           [  4,   7,   5]],\n",
              "  \n",
              "          [[ 23,  34,  39],\n",
              "           [ 27,  38,  43],\n",
              "           [ 25,  36,  41],\n",
              "           ...,\n",
              "           [ 19,  20,  24],\n",
              "           [  4,   6,   3],\n",
              "           [  5,   7,   3]],\n",
              "  \n",
              "          [[ 28,  41,  47],\n",
              "           [ 30,  43,  50],\n",
              "           [ 32,  45,  52],\n",
              "           ...,\n",
              "           [  5,   6,   8],\n",
              "           [  4,   5,   3],\n",
              "           [  7,   8,   7]]],\n",
              "  \n",
              "  \n",
              "         ...,\n",
              "  \n",
              "  \n",
              "         [[[ 20,  15,  12],\n",
              "           [ 19,  14,  11],\n",
              "           [ 15,  14,  11],\n",
              "           ...,\n",
              "           [ 10,   9,   7],\n",
              "           [ 12,  11,   9],\n",
              "           [ 13,  12,  10]],\n",
              "  \n",
              "          [[ 21,  16,  13],\n",
              "           [ 20,  16,  13],\n",
              "           [ 18,  17,  12],\n",
              "           ...,\n",
              "           [ 10,   9,   7],\n",
              "           [ 10,   9,   7],\n",
              "           [ 12,  11,   9]],\n",
              "  \n",
              "          [[ 21,  16,  13],\n",
              "           [ 21,  17,  12],\n",
              "           [ 20,  18,  11],\n",
              "           ...,\n",
              "           [ 12,  11,   9],\n",
              "           [ 12,  11,   9],\n",
              "           [ 13,  12,  10]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 33,  25,  13],\n",
              "           [ 34,  26,  15],\n",
              "           [ 34,  26,  15],\n",
              "           ...,\n",
              "           [ 28,  25,  52],\n",
              "           [ 29,  25,  58],\n",
              "           [ 23,  20,  42]],\n",
              "  \n",
              "          [[ 33,  25,  14],\n",
              "           [ 34,  26,  15],\n",
              "           [ 34,  26,  15],\n",
              "           ...,\n",
              "           [ 27,  24,  52],\n",
              "           [ 27,  24,  56],\n",
              "           [ 25,  22,  47]],\n",
              "  \n",
              "          [[ 31,  23,  12],\n",
              "           [ 32,  24,  13],\n",
              "           [ 33,  25,  14],\n",
              "           ...,\n",
              "           [ 24,  23,  50],\n",
              "           [ 26,  23,  53],\n",
              "           [ 25,  20,  47]]],\n",
              "  \n",
              "  \n",
              "         [[[ 25,  40,  12],\n",
              "           [ 15,  36,   3],\n",
              "           [ 23,  41,  18],\n",
              "           ...,\n",
              "           [ 61,  82,  78],\n",
              "           [ 92, 113, 112],\n",
              "           [ 75,  89,  92]],\n",
              "  \n",
              "          [[ 12,  25,   6],\n",
              "           [ 20,  37,   7],\n",
              "           [ 24,  36,  15],\n",
              "           ...,\n",
              "           [115, 134, 138],\n",
              "           [149, 168, 177],\n",
              "           [104, 117, 131]],\n",
              "  \n",
              "          [[ 12,  25,  11],\n",
              "           [ 15,  29,   6],\n",
              "           [ 34,  40,  24],\n",
              "           ...,\n",
              "           [154, 172, 182],\n",
              "           [157, 175, 192],\n",
              "           [116, 129, 151]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[100, 129,  81],\n",
              "           [103, 132,  84],\n",
              "           [104, 134,  86],\n",
              "           ...,\n",
              "           [ 97, 128,  84],\n",
              "           [ 98, 126,  84],\n",
              "           [ 91, 121,  79]],\n",
              "  \n",
              "          [[103, 132,  83],\n",
              "           [104, 131,  83],\n",
              "           [107, 135,  87],\n",
              "           ...,\n",
              "           [101, 132,  87],\n",
              "           [ 99, 127,  84],\n",
              "           [ 92, 121,  79]],\n",
              "  \n",
              "          [[ 95, 126,  78],\n",
              "           [ 95, 123,  76],\n",
              "           [101, 128,  81],\n",
              "           ...,\n",
              "           [ 93, 124,  80],\n",
              "           [ 95, 123,  81],\n",
              "           [ 92, 120,  80]]],\n",
              "  \n",
              "  \n",
              "         [[[ 73,  78,  75],\n",
              "           [ 98, 103, 113],\n",
              "           [ 99, 106, 114],\n",
              "           ...,\n",
              "           [135, 150, 152],\n",
              "           [135, 149, 154],\n",
              "           [203, 215, 223]],\n",
              "  \n",
              "          [[ 69,  73,  70],\n",
              "           [ 84,  89,  97],\n",
              "           [ 68,  75,  81],\n",
              "           ...,\n",
              "           [ 85,  95,  89],\n",
              "           [ 71,  82,  80],\n",
              "           [120, 133, 135]],\n",
              "  \n",
              "          [[ 69,  73,  70],\n",
              "           [ 90,  95, 100],\n",
              "           [ 62,  71,  74],\n",
              "           ...,\n",
              "           [ 74,  81,  70],\n",
              "           [ 53,  62,  54],\n",
              "           [ 62,  74,  69]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[123, 128,  96],\n",
              "           [132, 132, 102],\n",
              "           [129, 128, 100],\n",
              "           ...,\n",
              "           [108, 107,  88],\n",
              "           [ 62,  60,  55],\n",
              "           [ 27,  27,  28]],\n",
              "  \n",
              "          [[115, 121,  91],\n",
              "           [123, 124,  95],\n",
              "           [129, 126,  99],\n",
              "           ...,\n",
              "           [115, 116,  94],\n",
              "           [ 66,  65,  59],\n",
              "           [ 27,  27,  27]],\n",
              "  \n",
              "          [[116, 120,  90],\n",
              "           [121, 122,  94],\n",
              "           [129, 128, 101],\n",
              "           ...,\n",
              "           [116, 115,  94],\n",
              "           [ 68,  65,  58],\n",
              "           [ 27,  26,  26]]]], dtype=uint8), array([[3],\n",
              "         [8],\n",
              "         [8],\n",
              "         ...,\n",
              "         [5],\n",
              "         [1],\n",
              "         [7]], dtype=uint8)))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "KDM_KiriIUoC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rFtlZws6Tvy"
      },
      "source": [
        "#### Load and standardize the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn4KkplZ6Tvz",
        "outputId": "82a9a6c8-c76e-43ee-d438-8c38fc652639"
      },
      "source": [
        "# load the data, and separate it into train and test sets\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "\"\"\"\n",
        "print(len(train_images))\n",
        "print(len(test_images))\n",
        "print(len(train_labels), train_labels.shape)\n",
        "print(train_labels[:10])\n",
        "\"\"\"\n",
        "# Standardize the data\n",
        "print(\"Before\")\n",
        "print(f'Train images shape: {train_images.shape}')\n",
        "print(f'Train test images shape: {test_images.shape}')\n",
        "\n",
        "\n",
        "# flatten arrays -->Pasarme a un vector  a una lista después del flatten\n",
        "train_images = train_images.reshape((50000, 32 * 32* 3))\n",
        "print('After')\n",
        "print(f'Train images shape: {train_images.shape}')\n",
        "\n",
        "\n",
        "\n",
        "# turn values from 0-255 to 0-1\n",
        "train_images = train_images.astype('float32') / 255 \n",
        "\n",
        "# same starndadization for the test images\n",
        "test_images = test_images.reshape((10000, 32 * 32*3)) \n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "print(f'Train test shape: {test_images.shape}')\n",
        "# # one hot encoding\n",
        "train_labels = to_categorical(train_labels) \n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "print(train_labels[:10])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before\n",
            "Train images shape: (50000, 32, 32, 3)\n",
            "Train test images shape: (10000, 32, 32, 3)\n",
            "After\n",
            "Train images shape: (50000, 3072)\n",
            "Train test shape: (10000, 3072)\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGr2fmIh6Tvz"
      },
      "source": [
        "#### Create and compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf2HwoJe6Tv0",
        "outputId": "1004fa09-9464-4187-e38c-5a2d8cb76079"
      },
      "source": [
        "# The keras.models.Sequential class is a wrapper for the neural network model that treats \n",
        "# the network as a sequence of layers\n",
        "network = models.Sequential()\n",
        "\n",
        "# Dense layers: fully connected layers\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(32 * 32*3,)))\n",
        "network.add(layers.Dense(256, activation='relu'))\n",
        "network.add(layers.Dense(128, activation='relu'))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Once we have our model built, we need to compile it before it can be run. \n",
        "# Compiling the Keras model calls the backend (tensorflow, theano, etc.) and binds the optimizer, \n",
        "# loss function, and other parameters required before the model can be run on any input data.\n",
        "\n",
        "# loss function: basically, the error function. categorical crossentropy is one of many.\n",
        "\n",
        "\n",
        "# optimizer: this is the mechanism through which the network will update itself.\n",
        "# Stochastic Gradient descent (sgd) is one of those.\n",
        "\n",
        "# Metrics to monitor during training and testing. Here we will only care about accuracy.\n",
        "network.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "network.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               1573376   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WXt98Za6Tv0"
      },
      "source": [
        "#### Train the model\n",
        "\n",
        "The model is trained with the fit() method, through the following command that specifies the number of training epochs and the message level (how much information we want displayed on the screen during training)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPXWo-wu6Tv1",
        "outputId": "4244ae86-b8db-4183-825c-03d325313289"
      },
      "source": [
        "network.fit(train_images, train_labels, epochs=50)\n",
        "#network.fit(train_images, train_labels, epochs=50,validation_split=0.2)\n",
        "\n",
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "\n",
        "print(\"test loss: \", test_loss, \"test accuracy: \", test_acc)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 8s 3ms/step - loss: 1.8705 - accuracy: 0.3259\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6836 - accuracy: 0.3988\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5995 - accuracy: 0.4294\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5373 - accuracy: 0.4527\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4879 - accuracy: 0.4723\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4459 - accuracy: 0.4850\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4092 - accuracy: 0.4981\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3762 - accuracy: 0.5109\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3475 - accuracy: 0.5218\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3205 - accuracy: 0.5295\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2948 - accuracy: 0.5403\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2685 - accuracy: 0.5494\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2448 - accuracy: 0.5599\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2226 - accuracy: 0.5689\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1957 - accuracy: 0.5758\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1767 - accuracy: 0.5835\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1534 - accuracy: 0.5934\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1368 - accuracy: 0.5980\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1130 - accuracy: 0.6058\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0954 - accuracy: 0.6131\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0756 - accuracy: 0.6186\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0530 - accuracy: 0.6269\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0351 - accuracy: 0.6336\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0144 - accuracy: 0.6406\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9944 - accuracy: 0.6472\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9734 - accuracy: 0.6548\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9563 - accuracy: 0.6621\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9360 - accuracy: 0.6671\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9199 - accuracy: 0.6742\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9013 - accuracy: 0.6792\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8796 - accuracy: 0.6890\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8611 - accuracy: 0.6946\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8403 - accuracy: 0.7017\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8233 - accuracy: 0.7095\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8063 - accuracy: 0.7138\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7869 - accuracy: 0.7204\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7672 - accuracy: 0.7304\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7514 - accuracy: 0.7334\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7337 - accuracy: 0.7411\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7188 - accuracy: 0.7427\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6977 - accuracy: 0.7508\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6789 - accuracy: 0.7586\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6621 - accuracy: 0.7651\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6408 - accuracy: 0.7732\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6283 - accuracy: 0.7787\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6120 - accuracy: 0.7846\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5936 - accuracy: 0.7884\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5761 - accuracy: 0.7961\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5628 - accuracy: 0.8012\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5476 - accuracy: 0.8063\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.6971 - accuracy: 0.5386\n",
            "test loss:  1.6970798969268799 test accuracy:  0.5386000275611877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "rLZ5bNAd6Tv1",
        "outputId": "d3ffb6e3-038e-46c4-f117-a293b7c4b99f"
      },
      "source": [
        "# make a prediction on a specific image from the test data\n",
        "#test_index = 8\n",
        "import random\n",
        "test_index=random.randint(0, 10000)\n",
        "\n",
        "input_image = test_images[test_index].reshape(32*32*3)\n",
        "prediction = network.predict(np.array([input_image]))\n",
        "\n",
        "np.set_printoptions(precision=3, suppress= True)\n",
        "print(prediction, test_labels[test_index])\n",
        "\n",
        "plt.title(\"Label: \" + str(test_labels[test_index]))\n",
        "plt.imshow(test_images[test_index].reshape(32,32,3), cmap=\"gray\")\n",
        "#[0 ,1 ,2 ,3 ,4 ,5 ,6 ,7, 8, 9]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.002 0.912 0.    0.017 0.    0.037 0.001 0.    0.009 0.022]] [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5d662a2d10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}